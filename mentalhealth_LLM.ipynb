{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3de558",
   "metadata": {},
   "source": [
    "# 1. Set Environment & Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf2fdf",
   "metadata": {},
   "source": [
    "## 1-1. Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a9a54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s2hnpark/mentalhealth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/media/data/park\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/media/data/park\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/media/data/park\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd8073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN: hf_xZEqvBg\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "print(f\"HF_TOKEN: {hf_token[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf74c8e",
   "metadata": {},
   "source": [
    "## 1-2. Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141074cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2hnpark/.local/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf69228",
   "metadata": {},
   "source": [
    "# 2. Reform Dataset according to Llama3 template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d5707",
   "metadata": {},
   "source": [
    "## In case of Llama3.2B, the following prompt template is used for the chat models\n",
    "\n",
    "System Prompt (optional) to guide the model<br>\n",
    "User prompt (required) to give the instruction<br>\n",
    "Model Answer (required)<br>\n",
    "\n",
    "\\<s>[INST] \\<\\<SYS>> <br>\n",
    "System Prompt <br>\n",
    "\\<\\</SYS>> <br>\n",
    "\n",
    "User Prompt [/INST] Model Answer \\</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d20bf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Context  \\\n",
      "0     I'm going through some things with my feelings...   \n",
      "1     I'm going through some things with my feelings...   \n",
      "2     I'm going through some things with my feelings...   \n",
      "3     I'm going through some things with my feelings...   \n",
      "4     I'm going through some things with my feelings...   \n",
      "...                                                 ...   \n",
      "3507  My grandson's step-mother sends him to school ...   \n",
      "3508  My boyfriend is in recovery from drug addictio...   \n",
      "3509  The birth mother attempted suicide several tim...   \n",
      "3510  I think adult life is making him depressed and...   \n",
      "3511  I just took a job that requires me to travel f...   \n",
      "\n",
      "                                               Response  \n",
      "0     If everyone thinks you're worthless, then mayb...  \n",
      "1     Hello, and thank you for your question and see...  \n",
      "2     First thing I'd suggest is getting the sleep y...  \n",
      "3     Therapy is essential for those that are feelin...  \n",
      "4     I first want to let you know that you are not ...  \n",
      "...                                                 ...  \n",
      "3507  Absolutely not! It is never in a child's best ...  \n",
      "3508  I'm sorry you have tension between you and you...  \n",
      "3509  The true answer is, \"no one can really say wit...  \n",
      "3510  How do you help yourself to believe you requir...  \n",
      "3511                           hmm this is a tough one!  \n",
      "\n",
      "[3512 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f2a62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
      "   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n",
      "   How can I change my feeling of being worthless to everyone? [/INST] If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.\n",
      "---------\n",
      "I just took a job that requires me to travel far away from home. My family and I really need this job.\n",
      "\n",
      "People keep telling me I have \"anxiety\" and I'm terrified of having an anxiety attack on the road. This is all new to me. What can I do? [/INST] hmm this is a tough one!\n",
      "---------\n",
      "                                                Context  \\\n",
      "0     I'm going through some things with my feelings...   \n",
      "1     I'm going through some things with my feelings...   \n",
      "2     I'm going through some things with my feelings...   \n",
      "3     I'm going through some things with my feelings...   \n",
      "4     I'm going through some things with my feelings...   \n",
      "...                                                 ...   \n",
      "3507  My grandson's step-mother sends him to school ...   \n",
      "3508  My boyfriend is in recovery from drug addictio...   \n",
      "3509  The birth mother attempted suicide several tim...   \n",
      "3510  I think adult life is making him depressed and...   \n",
      "3511  I just took a job that requires me to travel f...   \n",
      "\n",
      "                                               Response  \\\n",
      "0     If everyone thinks you're worthless, then mayb...   \n",
      "1     Hello, and thank you for your question and see...   \n",
      "2     First thing I'd suggest is getting the sleep y...   \n",
      "3     Therapy is essential for those that are feelin...   \n",
      "4     I first want to let you know that you are not ...   \n",
      "...                                                 ...   \n",
      "3507  Absolutely not! It is never in a child's best ...   \n",
      "3508  I'm sorry you have tension between you and you...   \n",
      "3509  The true answer is, \"no one can really say wit...   \n",
      "3510  How do you help yourself to believe you requir...   \n",
      "3511                           hmm this is a tough one!   \n",
      "\n",
      "                                                    new  \n",
      "0     I'm going through some things with my feelings...  \n",
      "1     I'm going through some things with my feelings...  \n",
      "2     I'm going through some things with my feelings...  \n",
      "3     I'm going through some things with my feelings...  \n",
      "4     I'm going through some things with my feelings...  \n",
      "...                                                 ...  \n",
      "3507  My grandson's step-mother sends him to school ...  \n",
      "3508  My boyfriend is in recovery from drug addictio...  \n",
      "3509  The birth mother attempted suicide several tim...  \n",
      "3510  I think adult life is making him depressed and...  \n",
      "3511  I just took a job that requires me to travel f...  \n",
      "\n",
      "[3512 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"new\"] = df[df.columns[0:]].apply(\n",
    "    lambda x: \" [/INST] \".join(x.dropna().astype(str)),\n",
    "    axis=1\n",
    ")\n",
    "print(f\"{df['new'][0]}\\n---------\")\n",
    "print(f\"{df['new'][3511]}\\n---------\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6594153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\n",
      "   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\n",
      "   How can I change my feeling of being worthless to everyone? [/INST] If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today. </s>\n"
     ]
    }
   ],
   "source": [
    "df[\"new\"] = df[\"new\"].apply(lambda t: f\"<s>[INST] {t} </s>\")\n",
    "\n",
    "print(df[\"new\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f923d6a",
   "metadata": {},
   "source": [
    "Tokenize datasets with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c4c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-1B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe826056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new': \"<s>[INST] I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone? [/INST] If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\xa0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\xa0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\xa0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today. </s>\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['new'],\n",
       "    num_rows: 3512\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "data = {\"new\": df[\"new\"][:]}\n",
    "dataset = Dataset.from_dict(data)\n",
    "print(dataset[0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce84421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['new'],\n",
      "        num_rows: 3512\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = DatasetDict({\"train\": dataset})\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fee99f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'new': \"<s>[INST] I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone? [/INST] If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media. \\xa0Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living. \\xa0They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible. \\xa0 Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today. </s>\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dict[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a37c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "166847d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "      <th>new</th>\n",
       "      <th>num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "      <td>&lt;s&gt;[INST] I'm going through some things with m...</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "      <td>&lt;s&gt;[INST] I'm going through some things with m...</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "      <td>&lt;s&gt;[INST] I'm going through some things with m...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "      <td>&lt;s&gt;[INST] I'm going through some things with m...</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "      <td>&lt;s&gt;[INST] I'm going through some things with m...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>My grandson's step-mother sends him to school ...</td>\n",
       "      <td>Absolutely not! It is never in a child's best ...</td>\n",
       "      <td>&lt;s&gt;[INST] My grandson's step-mother sends him ...</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>My boyfriend is in recovery from drug addictio...</td>\n",
       "      <td>I'm sorry you have tension between you and you...</td>\n",
       "      <td>&lt;s&gt;[INST] My boyfriend is in recovery from dru...</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>The birth mother attempted suicide several tim...</td>\n",
       "      <td>The true answer is, \"no one can really say wit...</td>\n",
       "      <td>&lt;s&gt;[INST] The birth mother attempted suicide s...</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>I think adult life is making him depressed and...</td>\n",
       "      <td>How do you help yourself to believe you requir...</td>\n",
       "      <td>&lt;s&gt;[INST] I think adult life is making him dep...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>I just took a job that requires me to travel f...</td>\n",
       "      <td>hmm this is a tough one!</td>\n",
       "      <td>&lt;s&gt;[INST] I just took a job that requires me t...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3512 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Context  \\\n",
       "0     I'm going through some things with my feelings...   \n",
       "1     I'm going through some things with my feelings...   \n",
       "2     I'm going through some things with my feelings...   \n",
       "3     I'm going through some things with my feelings...   \n",
       "4     I'm going through some things with my feelings...   \n",
       "...                                                 ...   \n",
       "3507  My grandson's step-mother sends him to school ...   \n",
       "3508  My boyfriend is in recovery from drug addictio...   \n",
       "3509  The birth mother attempted suicide several tim...   \n",
       "3510  I think adult life is making him depressed and...   \n",
       "3511  I just took a job that requires me to travel f...   \n",
       "\n",
       "                                               Response  \\\n",
       "0     If everyone thinks you're worthless, then mayb...   \n",
       "1     Hello, and thank you for your question and see...   \n",
       "2     First thing I'd suggest is getting the sleep y...   \n",
       "3     Therapy is essential for those that are feelin...   \n",
       "4     I first want to let you know that you are not ...   \n",
       "...                                                 ...   \n",
       "3507  Absolutely not! It is never in a child's best ...   \n",
       "3508  I'm sorry you have tension between you and you...   \n",
       "3509  The true answer is, \"no one can really say wit...   \n",
       "3510  How do you help yourself to believe you requir...   \n",
       "3511                           hmm this is a tough one!   \n",
       "\n",
       "                                                    new  num_tokens  \n",
       "0     <s>[INST] I'm going through some things with m...         277  \n",
       "1     <s>[INST] I'm going through some things with m...         528  \n",
       "2     <s>[INST] I'm going through some things with m...         150  \n",
       "3     <s>[INST] I'm going through some things with m...         249  \n",
       "4     <s>[INST] I'm going through some things with m...         150  \n",
       "...                                                 ...         ...  \n",
       "3507  <s>[INST] My grandson's step-mother sends him ...         209  \n",
       "3508  <s>[INST] My boyfriend is in recovery from dru...         222  \n",
       "3509  <s>[INST] The birth mother attempted suicide s...         229  \n",
       "3510  <s>[INST] I think adult life is making him dep...         145  \n",
       "3511  <s>[INST] I just took a job that requires me t...          77  \n",
       "\n",
       "[3512 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numbers of tokens after Tokenizing.\n",
    "def count_tokens(row: dict) -> int:\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row[\"new\"],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False\n",
    "        )[\"input_ids\"]\n",
    "    )\n",
    "\n",
    "df[\"num_tokens\"] = df.apply(count_tokens, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fda9eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all three datasets\n",
    "def preprocess(dataset):\n",
    "    tokenized = tokenizer(dataset[\"new\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3156d291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2193d6a3c4154493bdcfa847ca258d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_dataset: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['new', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3512\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset_dict.map(preprocess, batched=True)\n",
    "print(f\"tokenized_dataset: {tokenized_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fe57c",
   "metadata": {},
   "source": [
    "Quantizate model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b4cb3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['bnb_4bit_compute_type']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    }
   ],
   "source": [
    "# Apply 4-bit quantization to reduce the model's memory footprint\n",
    "# Qunatization is a technique to reduce the precision of the model's weigts, which can significantly reduce memory usage and speed up inference.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_type=\"float16\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc1603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\", \n",
    "    offload_folder=\"offload\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40ae40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,703,936 || all params: 1,237,518,336 || trainable%: 0.1377\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "qlora_model = get_peft_model(model, lora_config)\n",
    "qlora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965716fe",
   "metadata": {},
   "source": [
    "Configurate Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f542efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/media/data/park\",\n",
    "    logging_dir=\"/media/data/park\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    num_train_epochs=1,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048940d",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81f0e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a34282d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=qlora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "110e7991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlightgreenworld\u001b[0m (\u001b[33mlightgreenworld-universit-t-trier\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.23.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/s2hnpark/mentalhealth/wandb/run-20251112_213128-60bqzmvf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lightgreenworld-universit-t-trier/huggingface/runs/60bqzmvf' target=\"_blank\">/media/data/park</a></strong> to <a href='https://wandb.ai/lightgreenworld-universit-t-trier/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lightgreenworld-universit-t-trier/huggingface' target=\"_blank\">https://wandb.ai/lightgreenworld-universit-t-trier/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lightgreenworld-universit-t-trier/huggingface/runs/60bqzmvf' target=\"_blank\">https://wandb.ai/lightgreenworld-universit-t-trier/huggingface/runs/60bqzmvf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2hnpark/.local/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:430: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 07:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19091fb",
   "metadata": {},
   "source": [
    "Save Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f17d6466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the fine-tuned model\n",
    "qlora_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43dd385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "# Test prompt\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=qlora_model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    # max_length=2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055d208",
   "metadata": {},
   "source": [
    "Use the text generation pipeline to ask questions like \"What is a large language model?\" <br>\n",
    "Note that I'm formatting the input to match Llama3.2 prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de53526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"<s>[INST] I barely sleep and I do nothing but think about how I'm worthless. [/INST] I think it is important to realize that you have some control over your thoughts. I also think it is important to realize that there is a difference between thoughts and feelings. Thoughts can be very powerful. It is very easy to think about how terrible you are. Thoughts can be very strong and intense. Thoughts can be very controlling. Thoughts can be very powerful.\\xa0I also think that it is important to realize that you can have control over your thoughts. Thoughts can be very powerful, but they can also be very easy to control.\\xa0If you can find a way to stop thinking about how worthless you are, and start thinking about what you have to be thankful for, and start thinking about what you are thankful for, and start thinking about what you are thankful for, and start thinking about what you are thankful for, and start thinking about how thankful you are, and start thinking about how thankful you are, and start thinking about how wonderful you are, and start thinking about how wonderful you are, and start thinking about how much you are appreciated, and start thinking about how much you are appreciated, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and start thinking about how much you appreciate yourself, and\"}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Format the prompt according to Llama3.2 template\n",
    "prompt = \"<s>[INST] I barely sleep and I do nothing but think about how I'm worthless. [/INST]\"\n",
    "\n",
    "outputs = generator(\n",
    "    prompt,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673051ec",
   "metadata": {},
   "source": [
    "Save the new model in GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "803688d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optimum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptimum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaCppModelForCausalLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 모델을 GGUF로 변환\u001b[39;00m\n\u001b[1;32m      4\u001b[0m LlamaCppModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fine-tuned/llama3.2-mentalhealth4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     export\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     export_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./gguf_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     quantization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq4_k_m\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optimum'"
     ]
    }
   ],
   "source": [
    "from optimum.llama_cpp import LlamaCppModelForCausalLM\n",
    "\n",
    "# 모델을 GGUF로 변환\n",
    "LlamaCppModelForCausalLM.from_pretrained(\n",
    "    \"./fine-tuned/llama3.2-mentalhealth4\",\n",
    "    export=True,\n",
    "    export_path=\"./gguf_model\",\n",
    "    quantization=\"q4_k_m\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm7Btrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
